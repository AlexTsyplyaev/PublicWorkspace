{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET PREPARED DATASET###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "data = pd.read_csv('./ENB2012_data.csv',engine = 'python',encoding='ascii')\n",
    "data.columns = [u'Relative Compactness',u'Surface Area',u'Wall Area',\n",
    "u'Roof Area',\n",
    "u'Overall Height',\n",
    "u'Orientation',\n",
    "u'Glazing Area',\n",
    "u'Glazing Area Distribution',\n",
    "u'Heating Load',\n",
    "u'Cooling Load']\n",
    "data_ = (data - data.mean(axis = 0))/data.std(axis = 0)\n",
    "for i in range (0,len(data_['Cooling Load'].values)):\n",
    "    data_['Cooling Load'].values[i]=int(data_['Cooling Load'].values[i])\n",
    "y= data_['Cooling Load']\n",
    "X = data_.drop(('Heating Load'), axis = 1).drop(('Cooling Load'), axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Splitted Data###\n",
    "import mysk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, \n",
    "                                                    random_state = 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235408560311 0.216535433071\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel = 'linear', C = 1)\n",
    "svc_model.fit(X_train, y_train)\n",
    "print (np.mean(y_train != svc_model.predict(X_train)), \\\n",
    "               np.mean(y_test != svc_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235408560311 0.216535433071\n",
      "0.235408560311 0.216535433071\n",
      "0.235408560311 0.216535433071\n",
      "0.190661478599 0.157480314961\n",
      "0.178988326848 0.192913385827\n",
      "0.147859922179 0.181102362205\n",
      "0.108949416342 0.165354330709\n",
      "0.0856031128405 0.157480314961\n",
      "0.210116731518 0.188976377953\n",
      "0.188715953307 0.196850393701\n",
      "0.155642023346 0.196850393701\n",
      "0.103112840467 0.153543307087\n",
      "0.309338521401 0.228346456693\n",
      "0.389105058366 0.303149606299\n",
      "0.373540856031 0.291338582677\n",
      "0.352140077821 0.259842519685\n"
     ]
    }
   ],
   "source": [
    "for i in [\"linear\",\"rbf\",\"poly\",\"sigmoid\"]:\n",
    "    for c in [1,3,7,20]:\n",
    "        svc_model = SVC(kernel = i, C = c)\n",
    "        svc_model.fit(X_train, y_train)\n",
    "        print (np.mean(y_train != svc_model.predict(X_train)), \\\n",
    "               np.mean(y_test != svc_model.predict(X_test)))\n",
    "#rbf and poly are ok with c=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22373540856 0.267716535433\n",
      "[[ 84  19   0   0]\n",
      " [ 13 257  41   0]\n",
      " [  0  24  58  18]\n",
      " [  0   0   0   0]]\n",
      "[[ 49  16   0   0]\n",
      " [  6 119  15   0]\n",
      " [  0  29  18   2]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alt_s/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda_model = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train.values, y_train.values)\n",
    "print (np.mean(y_train != lda_model.predict(X_train)), \\\n",
    "               np.mean(y_test != lda_model.predict(X_test)))\n",
    "print(confusion_matrix(lda_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(lda_model.predict(X_test), y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-df93374916be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmysk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmysk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_sep_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmysk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/PublicWorkspace/mysk.py\u001b[0m in \u001b[0;36mdraw_points\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_centers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "mysk.draw_points(X, y)\n",
    "mysk.draw_sep_curve(lda_model)\n",
    "mysk.draw_bayes()\n",
    "plt.scatter(lda_model.means_[:, 0], lda_model.means_[:, 1], color = ['b', 'r'], s = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332684824903 0.338582677165\n",
      "[[ 16   5   0   0]\n",
      " [ 81 274  46   6]\n",
      " [  0  21  53  12]\n",
      " [  0   0   0   0]]\n",
      "[[  3   1   0   0]\n",
      " [ 52 153  21   0]\n",
      " [  0  10  12   2]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alt_s/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qda_model = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train.values, y_train.values)\n",
    "print (np.mean(y_train != qda_model.predict(X_train)), \\\n",
    "               np.mean(y_test != qda_model.predict(X_test)))\n",
    "print(confusion_matrix(qda_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(qda_model.predict(X_test), y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643968871595 0.685039370079\n",
      "[[ 97 152   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0 146  68   0]\n",
      " [  0   2  31  18]]\n",
      "[[55 80  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0 83 23  0]\n",
      " [ 0  1 10  2]]\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "print (np.mean(y_train != nb_model.predict(X_train)), \\\n",
    "               np.mean(y_test != nb_model.predict(X_test)))\n",
    "print(confusion_matrix(nb_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(nb_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618677042802 0.653543307087\n",
      "[[ 97 152   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0 148  99  18]\n",
      " [  0   0   0   0]]\n",
      "[[55 80  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0 84 33  2]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "nbber_model = BernoulliNB()\n",
    "nbber_model.fit(X_train, y_train)\n",
    "print (np.mean(y_train != nbber_model.predict(X_train)), \\\n",
    "               np.mean(y_test != nbber_model.predict(X_test)))\n",
    "print(confusion_matrix(nbber_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(nbber_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12840466926070038"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_array = np.arange(1, 100)\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "grid = GridSearchCV(tree_model, param_grid = {'max_depth': depth_array}, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "min_err_cv = 1 - grid.best_score_\n",
    "min_err_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.106299212598\n",
      "[[ 97   0   0   0]\n",
      " [  0 300   0   0]\n",
      " [  0   0  99   0]\n",
      " [  0   0   0  18]]\n",
      "[[ 53   9   0   0]\n",
      " [  2 144   5   0]\n",
      " [  0  11  28   0]\n",
      " [  0   0   0   2]]\n"
     ]
    }
   ],
   "source": [
    "tree_model = tree.DecisionTreeClassifier(max_depth = None)\n",
    "tree_model.fit(X_train, y_train)\n",
    "print (np.mean(y_train != tree_model.predict(X_train)), \\\n",
    "               np.mean(y_test != tree_model.predict(X_test)))\n",
    "print(confusion_matrix(tree_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(tree_model.predict(X_test), y_test))\n",
    "#Wow, such power, many efficiency, so knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.198443579767 0.157480314961\n",
      "[[ 76  14   0   0]\n",
      " [ 21 278  41   0]\n",
      " [  0   8  58  18]\n",
      " [  0   0   0   0]]\n",
      "[[ 44  10   0   0]\n",
      " [ 11 146   9   0]\n",
      " [  0   8  24   2]\n",
      " [  0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(C=1.0)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "print (np.mean(y_train != logistic_model.predict(X_train)), \\\n",
    "               np.mean(y_test != logistic_model.predict(X_test)))\n",
    "print(confusion_matrix(logistic_model.predict(X_train), y_train))\n",
    "print(confusion_matrix(logistic_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
